{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [在 Lai嘎 AI 中，可以通过故事点、工时等多种方式进行迭代预估和排期] and saved to file.\n",
      "Speech synthesized for text [团队管理中，可以看到团队成员工作量和工作状态。] and saved to file.\n",
      "Speech synthesized for text [对于超负荷成员，通过拖拽方式变更任务执行者，实现任务的重新分配。] and saved to file.\n",
      "Speech synthesized for text [从而控制项目风险，提高项目成功率] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "texts = [\n",
    "    \"Lai嘎 AI 中，可以通过故事点、工时等多种方式进行迭代预估和排期\",\n",
    "    \"团队管理中，可以看到团队成员工作量和工作状态。\",\n",
    "    \"对于超负荷成员，通过拖拽方式变更任务执行者，实现任务的重新分配。\",\n",
    "    \"从而控制项目风险，提高项目成功率\"\n",
    "]\n",
    "\n",
    "for n, text in enumerate(texts):\n",
    "    # Instead of using the default speaker, specify a file to write the output\n",
    "    audio_output = speechsdk.audio.AudioOutputConfig(filename=f\"output/Xiaochen/00{n+1}.wav\")\n",
    "\n",
    "    # Use a neural voice for synthesis\n",
    "    speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "    # speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "    # Create the speech synthesizer with the specified speech and audio configurations\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "    # Perform the text-to-speech synthesis\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "    # Check the result of the synthesis operation\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"Speech synthesized for text [{text}] and saved to file.\")\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [LigaAI 能够实时反馈当前项目进度，包括燃尽图、燃起图、累计流图等] and saved to file.\n",
      "Speech synthesized for text [项目看板中，能够实时看到迭代中的故事和缺陷的状态] and saved to file.\n",
      "Speech synthesized for text [除此之外，LigaAI的智能体小助手可以对项目进行风险预警，项目经理可通过聊天的方式获取到最新信息] and saved to file.\n",
      "Speech synthesized for text [并且可以下钻到对应需求，及时推进项目进度] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "texts = [\n",
    "    \"LigaAI 能够实时反馈当前项目进度，包括燃尽图、燃起图、累计流图等\",\n",
    "    \"项目看板中，能够实时看到迭代中的故事和缺陷的状态\",\n",
    "    \"除此之外，LigaAI的智能体小助手可以对项目进行风险预警，项目经理可通过聊天的方式获取到最新信息\",\n",
    "    \"并且可以下钻到对应需求，及时推进项目进度\"\n",
    "]\n",
    "\n",
    "for n, text in enumerate(texts):\n",
    "    # Instead of using the default speaker, specify a file to write the output\n",
    "    audio_output = speechsdk.audio.AudioOutputConfig(filename=f\"output/Xiaochen/00{n+1}.wav\")\n",
    "\n",
    "    # Use a neural voice for synthesis\n",
    "    speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "    # speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "    # Create the speech synthesizer with the specified speech and audio configurations\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "    # Perform the text-to-speech synthesis\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "    # Check the result of the synthesis operation\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"Speech synthesized for text [{text}] and saved to file.\")\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [LigaAI 文档中内嵌了AI，可以辅助用户写作。] and saved to file.\n",
      "Speech synthesized for text [支持生成文字，也支持生成流程图。] and saved to file.\n",
      "Speech synthesized for text [除此之外，LigaAI支持通过模板结构化生成文档，使得文档更符合企业需求] and saved to file.\n",
      "Speech synthesized for text [文档历史可查可回退，使得协作中被他人误删内容可找回] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "texts = [\n",
    "    \"LigaAI 文档中内嵌了AI，可以辅助用户写作。\",\n",
    "    \"支持生成文字，也支持生成流程图。\",\n",
    "    \"除此之外，LigaAI支持通过模板结构化生成文档，使得文档更符合企业需求\",\n",
    "    \"文档历史可查可回退，使得协作中被他人误删内容可找回\"\n",
    "]\n",
    "\n",
    "for n, text in enumerate(texts):\n",
    "    # Instead of using the default speaker, specify a file to write the output\n",
    "    audio_output = speechsdk.audio.AudioOutputConfig(filename=f\"output/Xiaochen/00{n+1}.wav\")\n",
    "\n",
    "    # Use a neural voice for synthesis\n",
    "    speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "    # speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "    # Create the speech synthesizer with the specified speech and audio configurations\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "    # Perform the text-to-speech synthesis\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "    # Check the result of the synthesis operation\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"Speech synthesized for text [{text}] and saved to file.\")\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [LigaAI 支持RPA自动化流转，减少用户重复操作。] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "texts = [\n",
    "    \"LigaAI 支持RPA自动化流转，减少用户重复操作。\"\n",
    "]\n",
    "\n",
    "for n, text in enumerate(texts):\n",
    "    # Instead of using the default speaker, specify a file to write the output\n",
    "    audio_output = speechsdk.audio.AudioOutputConfig(filename=f\"output/Xiaochen/00{n+1}.wav\")\n",
    "\n",
    "    # Use a neural voice for synthesis\n",
    "    speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "    # speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "    # Create the speech synthesizer with the specified speech and audio configurations\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "    # Perform the text-to-speech synthesis\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "    # Check the result of the synthesis operation\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"Speech synthesized for text [{text}] and saved to file.\")\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [团队和个人智能周报让用户更了解项目情况；同时LigaAI的智能体可下穿看详情。] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "texts = [\n",
    "    \"团队和个人智能周报让用户更了解项目情况；同时LigaAI的智能体可下穿看详情。\"\n",
    "]\n",
    "\n",
    "for n, text in enumerate(texts):\n",
    "    # Instead of using the default speaker, specify a file to write the output\n",
    "    audio_output = speechsdk.audio.AudioOutputConfig(filename=f\"output/Xiaochen/00{n+1}.wav\")\n",
    "\n",
    "    # Use a neural voice for synthesis\n",
    "    speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "    # speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "    # Create the speech synthesizer with the specified speech and audio configurations\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "    # Perform the text-to-speech synthesis\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "    # Check the result of the synthesis operation\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"Speech synthesized for text [{text}] and saved to file.\")\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [当产品经理更新工作项的状态时，结果将立即同步到开发者常用的IDE中。] and saved to file.\n",
      "Speech synthesized for text [开发人员可以立即在IDE中开始工作，无需切换上下文。] and saved to file.\n",
      "Speech synthesized for text [过了一段时间后，开发人员更新了文件，这时候，他只需在当前IDE上点击一个按钮，就可以提交并标记功能完成。功能的需求ID自动填写在提交信息中。] and saved to file.\n",
      "Speech synthesized for text [点击提交和同步后，提交内容将更新到GitLab。形成需求和代码侧的同步。] and saved to file.\n",
      "Speech synthesized for text [同时，对应需求状态在LigaAI中更新。] and saved to file.\n",
      "Speech synthesized for text [作为一名开发者，我可以很轻松的检查我的编码时间和集中程度，以指导更高效的开发。] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "texts = [\n",
    "    \"当产品经理更新工作项的状态时，结果将立即同步到开发者常用的IDE中。\",\n",
    "    \"开发人员可以立即在IDE中开始工作，无需切换上下文。\",\n",
    "    \"过了一段时间后，开发人员更新了文件，这时候，他只需在当前IDE上点击一个按钮，就可以提交并标记功能完成。功能的需求ID自动填写在提交信息中。\",\n",
    "    \"点击提交和同步后，提交内容将更新到GitLab。形成需求和代码侧的同步。\",\n",
    "    \"同时，对应需求状态在LigaAI中更新。\",\n",
    "    \"作为一名开发者，我可以很轻松的检查我的编码时间和集中程度，以指导更高效的开发。\"\n",
    "]\n",
    "\n",
    "for n, text in enumerate(texts):\n",
    "    # Instead of using the default speaker, specify a file to write the output\n",
    "    audio_output = speechsdk.audio.AudioOutputConfig(filename=f\"output/Xiaochen/00{n+1}.wav\")\n",
    "\n",
    "    # Use a neural voice for synthesis\n",
    "    speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "    # speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "    # Create the speech synthesizer with the specified speech and audio configurations\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "    # Perform the text-to-speech synthesis\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "    # Check the result of the synthesis operation\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"Speech synthesized for text [{text}] and saved to file.\")\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-in-general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
