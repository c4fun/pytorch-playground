{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop a series of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [When writing documents, you may encounter problems such as slow in writing, poor quality, or high costs.] and saved to file.\n",
      "Speech synthesized for text [Docu-opia helps you solve these problems.] and saved to file.\n",
      "Speech synthesized for text [Don't know the outline? Let AI write it for you.] and saved to file.\n",
      "Speech synthesized for text [Have a more complex outline than a single sentence? Try editing your own template. Here you can use PRD template as well as test case template. And you can edit components of each template so as to cater to your need.] and saved to file.\n",
      "Speech synthesized for text [The AI does not access internet in default for your privacy protection. But if you want to access newer info, our AI can access the Internet on demand.] and saved to file.\n",
      "Speech synthesized for text [Experience speed, high quality, and cost-efficiency like never before. Don't wait! Transform your documentation experience with Docu-opia AI today!] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "texts = [\n",
    "    \"When writing documents, you may encounter problems such as slow in writing, poor quality, or high costs.\",\n",
    "    \"Docu-opia helps you solve these problems.\",\n",
    "    \"Don't know the outline? Let AI write it for you.\",\n",
    "    \"Have a more complex outline than a single sentence? Try editing your own template. Here you can use PRD template as well as test case template. And you can edit components of each template so as to cater to your need.\",\n",
    "    \"The AI does not access internet in default for your privacy protection. But if you want to access newer info, our AI can access the Internet on demand.\",\n",
    "    \"Experience speed, high quality, and cost-efficiency like never before. Don't wait! Transform your documentation experience with Docu-opia AI today!\"\n",
    "]\n",
    "\n",
    "for n, text in enumerate(texts):\n",
    "    # Instead of using the default speaker, specify a file to write the output\n",
    "    audio_output = speechsdk.audio.AudioOutputConfig(filename=f\"output/Xiaoxiao/00{n+1}.wav\")\n",
    "\n",
    "    # Use a neural voice for synthesis\n",
    "    # speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "    speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "    # Create the speech synthesizer with the specified speech and audio configurations\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "    # Perform the text-to-speech synthesis\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "    # Check the result of the synthesis operation\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"Speech synthesized for text [{text}] and saved to file.\")\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save it as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [When writing documents, you may encounter problems such as slow in writing, poor quality, or high costs.] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "\n",
    "# Instead of using the default speaker, specify a file to write the output\n",
    "audio_output = speechsdk.audio.AudioOutputConfig(filename=\"output/Xiaoxiao/001.wav\")\n",
    "\n",
    "# Use a neural voice for synthesis\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-AvaMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-EmmaMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-BrianMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-GuyNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-JennyNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-ElizabethNeural'\n",
    "\n",
    "\n",
    "speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-YunyiMultilingualNeural\"\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoyuMultilingualNeural\"\n",
    "\n",
    "# Create the speech synthesizer with the specified speech and audio configurations\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "# Get text from the console and synthesize to the specified file\n",
    "# print(\"Enter some text that you want to speak >\")\n",
    "# text = input()\n",
    "text = \"When writing documents, you may encounter problems such as slow in writing, poor quality, or high costs.\"\n",
    "\n",
    "# Perform the text-to-speech synthesis\n",
    "speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "# Check the result of the synthesis operation\n",
    "if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}] and saved to file.\".format(text))\n",
    "elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = speech_synthesis_result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try\n",
    "\n",
    "## Xiaoxiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [你好，这是晓晓。]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "  For more samples please visit https://github.com/Azure-Samples/cognitive-services-speech-sdk \n",
    "'''\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "# Note: the voice setting will not overwrite the voice element in input SSML.\n",
    "speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "text = \"你好，这是晓晓。\"\n",
    "\n",
    "# use the default speaker as audio output.\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "result = speech_synthesizer.speak_text_async(text).get()\n",
    "# Check result\n",
    "if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}]\".format(text))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text that you want to speak >\n",
      "Speech synthesized for text [hello. How are you?]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "\n",
    "# The neural multilingual voice can speak different languages based on the input text.\n",
    "speech_config.speech_synthesis_voice_name='en-US-AvaMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "# Get text from the console and synthesize to the default speaker.\n",
    "print(\"Enter some text that you want to speak >\")\n",
    "text = input()\n",
    "\n",
    "speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}]\".format(text))\n",
    "elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = speech_synthesis_result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-in-general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
