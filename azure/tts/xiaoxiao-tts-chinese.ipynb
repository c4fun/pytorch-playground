{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop a series of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [你是否还在为代码没有注释烦恼呢？你是否打开别人的代码之后不知所措呢？你是否有时也会忘了自己写的代码是什么意思呢？] and saved to file.\n",
      "Speech synthesized for text [那就用CyberGit来解决吧！一目十行，读懂代码。] and saved to file.\n",
      "Speech synthesized for text [以下几步操作，立马开始使用CyberGit：] and saved to file.\n",
      "Speech synthesized for text [访问 CyberGit点cn ， 点击注册。注册时需要输入正确的邮箱以接收验证码。] and saved to file.\n",
      "Speech synthesized for text [注册并验证登录成功之后，打开VSCode，在应用市场中找到CyberGit并安装。] and saved to file.\n",
      "Speech synthesized for text [在CyberGit插件页签中，点击登录按钮，使用刚刚注册的用户名、和、密码、登录。] and saved to file.\n",
      "Speech synthesized for text [登录成功之后，打开你想要访问的git代码仓库。] and saved to file.\n",
      "Speech synthesized for text [同时右下角应该切换为“CyberGit：开”的状态，表示CyberGit已经在运行。] and saved to file.\n",
      "Speech synthesized for text [点开需要访问的文件。如果这个代码仓库是在CyberGit中第一次访问，右下角会弹出窗口确认是否创建仓库，点击”是”即可。] and saved to file.\n",
      "Speech synthesized for text [CyberGit会自动检测此仓库的公网可见性，并询问用户是否创建仓库。视频中我们看到的是一个开源仓库，所以CyberGit会把它设置为一个公有仓库噢！此时，在右下角的弹出窗口中，点击“是”，确认创建。如果是不可访问的仓库，会自动设置为私有仓库，私有仓库在设置分享之前只对创建者可见。] and saved to file.\n",
      "Speech synthesized for text [点开你想要访问的文件。如果这个文件是第一次访问，则系统会读取文件并创建注释；根据文件大小，首次创建注释需要花费数十秒到数分钟时间。如果是已经访问的文件，则系统会立马弹出注释。] and saved to file.\n",
      "Speech synthesized for text [这样，你就可以在CyberGit的陪伴下，更高效的看代码啦！] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "texts = [\n",
    "    \"你是否还在为代码没有注释烦恼呢？你是否打开别人的代码之后不知所措呢？你是否有时也会忘了自己写的代码是什么意思呢？\",\n",
    "    \"那就用CyberGit来解决吧！一目十行，读懂代码。\",\n",
    "    \"以下几步操作，立马开始使用CyberGit：\",\n",
    "    \"访问 CyberGit点cn ， 点击注册。注册时需要输入正确的邮箱以接收验证码。\",\n",
    "    \"注册并验证登录成功之后，打开VSCode，在应用市场中找到CyberGit并安装。\",\n",
    "    \"在CyberGit插件页签中，点击登录按钮，使用刚刚注册的用户名、和、密码、登录。\",\n",
    "    \"登录成功之后，打开你想要访问的git代码仓库。\",\n",
    "    \"同时右下角应该切换为“CyberGit：开”的状态，表示CyberGit已经在运行。\",\n",
    "    \"点开需要访问的文件。如果这个代码仓库是在CyberGit中第一次访问，右下角会弹出窗口确认是否创建仓库，点击”是”即可。\",\n",
    "    \"CyberGit会自动检测此仓库的公网可见性，并询问用户是否创建仓库。视频中我们看到的是一个开源仓库，所以CyberGit会把它设置为一个公有仓库噢！此时，在右下角的弹出窗口中，点击“是”，确认创建。如果是不可访问的仓库，会自动设置为私有仓库，私有仓库在设置分享之前只对创建者可见。\",\n",
    "    \"点开你想要访问的文件。如果这个文件是第一次访问，则系统会读取文件并创建注释；根据文件大小，首次创建注释需要花费数十秒到数分钟时间。如果是已经访问的文件，则系统会立马弹出注释。\",\n",
    "    \"这样，你就可以在CyberGit的陪伴下，更高效的看代码啦！\"\n",
    "]\n",
    "\n",
    "for n, text in enumerate(texts):\n",
    "    # Instead of using the default speaker, specify a file to write the output\n",
    "    audio_output = speechsdk.audio.AudioOutputConfig(filename=f\"output/Xiaoxiao/cybergit-00{n+1}.wav\")\n",
    "\n",
    "    # Use a neural voice for synthesis\n",
    "    # speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "    speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "    # Create the speech synthesizer with the specified speech and audio configurations\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "    # Perform the text-to-speech synthesis\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "    # Check the result of the synthesis operation\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"Speech synthesized for text [{text}] and saved to file.\")\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save it as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [When writing documents, you may encounter problems such as slow in writing, poor quality, or high costs.] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "\n",
    "# Instead of using the default speaker, specify a file to write the output\n",
    "audio_output = speechsdk.audio.AudioOutputConfig(filename=\"output/Xiaoxiao/001.wav\")\n",
    "\n",
    "# Use a neural voice for synthesis\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-AvaMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-EmmaMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-BrianMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-GuyNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-JennyNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-ElizabethNeural'\n",
    "\n",
    "\n",
    "speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-YunyiMultilingualNeural\"\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoyuMultilingualNeural\"\n",
    "\n",
    "# Create the speech synthesizer with the specified speech and audio configurations\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "# Get text from the console and synthesize to the specified file\n",
    "# print(\"Enter some text that you want to speak >\")\n",
    "# text = input()\n",
    "text = \"When writing documents, you may encounter problems such as slow in writing, poor quality, or high costs.\"\n",
    "\n",
    "# Perform the text-to-speech synthesis\n",
    "speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "# Check the result of the synthesis operation\n",
    "if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}] and saved to file.\".format(text))\n",
    "elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = speech_synthesis_result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try\n",
    "\n",
    "## Xiaoxiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [你好，这是晓晓。]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "  For more samples please visit https://github.com/Azure-Samples/cognitive-services-speech-sdk \n",
    "'''\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "# Note: the voice setting will not overwrite the voice element in input SSML.\n",
    "speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "text = \"你好，这是晓晓。\"\n",
    "\n",
    "# use the default speaker as audio output.\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "result = speech_synthesizer.speak_text_async(text).get()\n",
    "# Check result\n",
    "if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}]\".format(text))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text that you want to speak >\n",
      "Speech synthesized for text [hello. How are you?]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "\n",
    "# The neural multilingual voice can speak different languages based on the input text.\n",
    "speech_config.speech_synthesis_voice_name='en-US-AvaMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "# Get text from the console and synthesize to the default speaker.\n",
    "print(\"Enter some text that you want to speak >\")\n",
    "text = input()\n",
    "\n",
    "speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}]\".format(text))\n",
    "elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = speech_synthesis_result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-in-general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
