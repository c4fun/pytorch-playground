{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop a series of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['画面1：', 'Hi，欢迎来到新一代智能研发协作平台LaigaAI平台']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"画面1：\n",
    "Hi，欢迎来到新一代智能研发协作平台LaigaAI平台\n",
    "这个视频，我将为你介绍LaigaAI如何帮助企业连接研发和业务\n",
    "更快、更流畅地响应客户需求\n",
    "打造更具价值的伟大产品\n",
    "画面2：\n",
    "在LaigaAI，你可以通过强大的集成能力\n",
    "集中管理不同渠道的用户反馈\n",
    "不让任何一条反馈石沉大海\n",
    "画面3：\n",
    "业务部门可以在日常沟通中\n",
    "快速把聊天信息转为LaigaAI中的用户反馈事项\n",
    "沉淀沟通成果\n",
    "画面4：\n",
    "产品研发部门会在IM机器人或群消息中收到即时提醒\n",
    "并根据对该事项的判断\n",
    "直接指派执行人、优先级、截止时间等信息\n",
    "确保用户问题得到及时的响应\n",
    "画面5：\n",
    "产品经理可以定期查收来自用户的全部声音\n",
    "采纳相关反馈后\n",
    "新的研发需求就会自动创建在产品开发项目的需求池中\n",
    "等待进入迭代规划\n",
    "画面6：\n",
    "作为执行人的开发人员\n",
    "日常在开发环境IDE上就能查看自己的开发任务\n",
    "通过插件快速提交代码\n",
    "LaigaAI就会自动捕捉提交信息\n",
    "自动推进任务流转\n",
    "画面7：\n",
    "随后当需求进入排期\n",
    "投入开发或被发布到线上\n",
    "每一步的进展都将和原始的用户反馈动态关联\n",
    "自动触达发起者\n",
    "快速连接终端用户\n",
    "告别黑盒，让研发与业务协作更紧密\n",
    "画面8：\n",
    "在推进项目成员流畅协作的同时\n",
    "LaigaAI还具备丰富的多项目管理能力\n",
    "通过路线图\n",
    "你可以在全局视角把握组织内各条产品线的里程碑、开发周期和进度收益等情况\n",
    "画面9：\n",
    "前往团队面板\n",
    "你可以准确地了解每个成员真实的工作饱和度\n",
    "调整分工\n",
    "以便更合理的进行资源统筹\n",
    "保证可持续的高质量交付\n",
    "画面10：\n",
    "LaigaAI 还贴心地为每一个人配备了 AI 助手\n",
    "你可在此更轻松地管理自己的工作\n",
    "并借由 AI 能力快速掌握项目进展和潜在风险\n",
    "画面11：\n",
    "还有仪表盘，为管理者呈现各项目各迭代当前的运转情况\n",
    "画面12：\n",
    "LaigaAI 洞察则从多维度提供科学的数据分析\n",
    "帮助管理者实时了解团队的健康状态\n",
    "AI 智能总结还能帮你快速掌握研发全貌\n",
    "识别潜在风险和短板\n",
    "并提供可实践的优化行动建议助力精准提效\n",
    "画面13：\n",
    "对于经常出差或移动办公的小伙伴\n",
    "则可以通过LaigaAI小程序\n",
    "随时关注项目动态\n",
    "响应工作消息\n",
    "画面14：\n",
    "新一代智能研发协作平台LaiGaAI打通多方信息\n",
    "拉近研发与业务的距离\n",
    "让价值交付更简单\n",
    "\"\"\"\n",
    "texts = text.splitlines()\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LaigaAI 洞察则从多维度提供科学的数据分析，帮助管理者实时了解团队的健康状态，动态跟踪整体表现及变化。', 'AI 智能总结还能帮你快速掌握研发全貌，识别潜在风险和短板，并提供可实践的优化行动建议助力精准提效。', '团队成员中，可以使用AI总结一目了然研发人员效能，帮助管理者决策']\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"LaigaAI 洞察则从多维度提供科学的数据分析，帮助管理者实时了解团队的健康状态，动态跟踪整体表现及变化。\n",
    "AI 智能总结还能帮你快速掌握研发全貌，识别潜在风险和短板，并提供可实践的优化行动建议助力精准提效。\n",
    "团队成员中，可以使用AI总结一目了然研发人员效能，帮助管理者决策\n",
    "\"\"\"\n",
    "texts = text.splitlines()\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [LaigaAI 洞察则从多维度提供科学的数据分析，帮助管理者实时了解团队的健康状态，动态跟踪整体表现及变化。] and saved to file.\n",
      "Speech synthesized for text [AI 智能总结还能帮你快速掌握研发全貌，识别潜在风险和短板，并提供可实践的优化行动建议助力精准提效。] and saved to file.\n",
      "Speech synthesized for text [团队成员中，可以使用AI总结一目了然研发人员效能，帮助管理者决策] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "# texts = [\n",
    "#     \"Hi，欢迎来到新一代智能研发协作平台LigaAI，\",\n",
    "#     \"这个视频，我将为你介绍LigaAI如何帮助企业连接研发和业务\",\n",
    "#     \"更快、更流畅地响应客户需求\",\n",
    "#     \"打造更具价值的伟大产品\",\n",
    "#     \"By utilizing agents and RAG knowledge base, Leiga provides project manager with accurate reports on projects. This includes aggregating work items by different clusters; tallying the points and workload.\",\n",
    "#     \"We can further dive into details with AI assistant. Thus project manager can use the detail to adjust the workload schedule accordingly.\",\n",
    "#     \"Leiga provides real-time R&D data BI and AI-powered Q&A, making project management more visual and more accurate. This enhances project control and ensures better manageability!\"\n",
    "# ]\n",
    "\n",
    "for n, text in enumerate(texts):\n",
    "    # Instead of using the default speaker, specify a file to write the output\n",
    "    audio_output = speechsdk.audio.AudioOutputConfig(filename=f\"output/Xiaoxiao/liga-00{n+1}.wav\")\n",
    "\n",
    "    # Use a neural voice for synthesis\n",
    "    # speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "    speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "    # Create the speech synthesizer with the specified speech and audio configurations\n",
    "    speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "    # Perform the text-to-speech synthesis\n",
    "    speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "    # Check the result of the synthesis operation\n",
    "    if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "        print(f\"Speech synthesized for text [{text}] and saved to file.\")\n",
    "    elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "        cancellation_details = speech_synthesis_result.cancellation_details\n",
    "        print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "        if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "            if cancellation_details.error_details:\n",
    "                print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "                print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save it as a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [When writing documents, you may encounter problems such as slow in writing, poor quality, or high costs.] and saved to file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "\n",
    "# Instead of using the default speaker, specify a file to write the output\n",
    "audio_output = speechsdk.audio.AudioOutputConfig(filename=\"output/Xiaoxiao/001.wav\")\n",
    "\n",
    "# Use a neural voice for synthesis\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-AvaMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-EmmaMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-BrianMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-GuyNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-JennyNeural'\n",
    "# speech_config.speech_synthesis_voice_name = 'en-US-ElizabethNeural'\n",
    "\n",
    "\n",
    "speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-YunyiMultilingualNeural\"\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-XiaochenMultilingualNeural\"\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoyuMultilingualNeural\"\n",
    "\n",
    "# Create the speech synthesizer with the specified speech and audio configurations\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_output)\n",
    "\n",
    "# Get text from the console and synthesize to the specified file\n",
    "# print(\"Enter some text that you want to speak >\")\n",
    "# text = input()\n",
    "text = \"When writing documents, you may encounter problems such as slow in writing, poor quality, or high costs.\"\n",
    "\n",
    "# Perform the text-to-speech synthesis\n",
    "speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "# Check the result of the synthesis operation\n",
    "if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}] and saved to file.\".format(text))\n",
    "elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = speech_synthesis_result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try\n",
    "\n",
    "## Xiaoxiao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech synthesized for text [你好，这是晓晓。]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "  For more samples please visit https://github.com/Azure-Samples/cognitive-services-speech-sdk \n",
    "'''\n",
    "\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "# Note: the voice setting will not overwrite the voice element in input SSML.\n",
    "speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "text = \"你好，这是晓晓。\"\n",
    "\n",
    "# use the default speaker as audio output.\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config)\n",
    "\n",
    "result = speech_synthesizer.speak_text_async(text).get()\n",
    "# Check result\n",
    "if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}]\".format(text))\n",
    "elif result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ava"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter some text that you want to speak >\n",
      "Speech synthesized for text [hello. How are you?]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the speech configuration with your Azure Speech service key and region\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.getenv(\"SPEECH_KEY\"),\n",
    "                                       region=os.getenv(\"SPEECH_REGION\"))\n",
    "audio_config = speechsdk.audio.AudioOutputConfig(use_default_speaker=True)\n",
    "\n",
    "# The neural multilingual voice can speak different languages based on the input text.\n",
    "speech_config.speech_synthesis_voice_name='en-US-AvaMultilingualNeural'\n",
    "# speech_config.speech_synthesis_voice_name = \"zh-CN-XiaoxiaoMultilingualNeural\"\n",
    "\n",
    "\n",
    "speech_synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "# Get text from the console and synthesize to the default speaker.\n",
    "print(\"Enter some text that you want to speak >\")\n",
    "text = input()\n",
    "\n",
    "speech_synthesis_result = speech_synthesizer.speak_text_async(text).get()\n",
    "\n",
    "if speech_synthesis_result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:\n",
    "    print(\"Speech synthesized for text [{}]\".format(text))\n",
    "elif speech_synthesis_result.reason == speechsdk.ResultReason.Canceled:\n",
    "    cancellation_details = speech_synthesis_result.cancellation_details\n",
    "    print(\"Speech synthesis canceled: {}\".format(cancellation_details.reason))\n",
    "    if cancellation_details.reason == speechsdk.CancellationReason.Error:\n",
    "        if cancellation_details.error_details:\n",
    "            print(\"Error details: {}\".format(cancellation_details.error_details))\n",
    "            print(\"Did you set the speech resource key and region values?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-in-general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
